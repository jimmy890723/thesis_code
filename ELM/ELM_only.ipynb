{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee6a7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2534e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8180ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['INFJ', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['INTP', 'INTP', 'INTP', 'ENTP', 'ENTP', 'ENTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['INTP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['INTP', 'ENTP', 'INTJ', 'INFP', 'INTJ', 'INTJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['ENTJ', 'ENTJ', 'ENTJ', 'ENTP', 'ENTJ', 'ENTJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ['INFJ', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INTP...\n",
       "1  ENTP  ['INTP', 'INTP', 'INTP', 'ENTP', 'ENTP', 'ENTP...\n",
       "2  INTP  ['INTP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP...\n",
       "3  INTJ  ['INTP', 'ENTP', 'INTJ', 'INFP', 'INTJ', 'INTJ...\n",
       "4  ENTJ  ['ENTJ', 'ENTJ', 'ENTJ', 'ENTP', 'ENTJ', 'ENTJ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/LSTM/mbti_to_LSTM_DF.csv')\n",
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/one_type_one_sentence/mbti_to_LSTM_DF.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27376d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0,\n",
    "                        'ENTP': 1,\n",
    "                        'INTP': 2,\n",
    "                        'INTJ': 3,\n",
    "                        'ENTJ': 4,\n",
    "                        'ENFJ': 5,\n",
    "                        'INFP': 6,\n",
    "                        'ENFP': 7,\n",
    "                        'ISFP': 8,\n",
    "                        'ISTP': 9,\n",
    "                        'ISFJ': 10,\n",
    "                        'ISTJ': 11,\n",
    "                        'ESTP': 12,\n",
    "                        'ESFP': 13,\n",
    "                        'ESTJ': 14,\n",
    "                        'ESFJ': 15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef7fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_counts = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0}\n",
    "    mbti_per_count = []\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    \n",
    "    for personality_id in dialogue_ids:\n",
    "        mbti_counts[personality_id] += 1\n",
    "    \n",
    "    for i in range(len(personality_mapping)):\n",
    "        mbti_per_count.append(round(mbti_counts[i]/len(dialogue_ids), 2))\n",
    "    \n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((mbti_per_count, target_personality_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67245650",
   "metadata": {},
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((dialogue_ids, target_personality_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbce5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列並轉換為張量\n",
    "input_data = torch.tensor([feature for feature, _ in encoded_data], dtype=torch.float32)\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.int64)  # 使用int64类型，因为它是类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464e2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集切分為訓練集和驗證集\n",
    "train_dialogues, X_temp, train_target, y_temp = train_test_split(input_data, target_personality, test_size=0.3, random_state=42)\n",
    "\n",
    "# 进一步划分剩余的数据为验证集和测试集\n",
    "val_dialogues, X_test, val_target, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#train_dialogues, val_dialogues, train_target, val_target = train_test_split(input_data, target_personality, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7f8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建反向映射\n",
    "reverse_personality_mapping = {v: k for k, v in personality_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b5564",
   "metadata": {},
   "source": [
    "similar_tag = 1 #控制多少個指標以下要捨棄 (1~4)\n",
    "total_del_count_times = 0\n",
    "for index, personality_num in enumerate(train_target):\n",
    "    del_count_times = 0\n",
    "    # 使用反向映射将数字转换为对应的个性\n",
    "    personality = reverse_personality_mapping.get(int(personality_num), \"Unknown\")\n",
    "    tmp_dialogues = train_dialogues[index]\n",
    "    for n in range(len(personality_mapping)):\n",
    "        counter = 0\n",
    "        for m in range(4):\n",
    "            if reverse_personality_mapping[n][m] == personality[m]:\n",
    "                counter += 1\n",
    "        if counter < similar_tag:\n",
    "            train_dialogues[index][n] = 0.0\n",
    "            del_count_times += 1\n",
    "            \n",
    "    # 计算所有非零值的总和\n",
    "    non_zero_sum = torch.sum(train_dialogues[index])\n",
    "\n",
    "    #如果都是0\n",
    "    if non_zero_sum == 0: \n",
    "        train_dialogues[index] = tmp_dialogues\n",
    "    else:  # 重新分配其他非零值，使它们的总和为1\n",
    "        train_dialogues[index] = train_dialogues[index] / non_zero_sum\n",
    "        total_del_count_times += del_count_times\n",
    "\n",
    "print(total_del_count_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0a4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將你的訓練數據和測試數據轉換為NumPy數組\n",
    "X_train = train_dialogues.numpy()\n",
    "y_train = train_target.numpy()\n",
    "X_val = val_dialogues.numpy()\n",
    "X_test = X_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a16654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04 0.07 0.7  0.02 0.   0.   0.15 0.02 0.   0.   0.   0.   0.   0.\n",
      " 0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a0c97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90a3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置類別數目\n",
    "num_classes = len(personality_mapping)\n",
    "\n",
    "# 將一維列表轉換為二維列表（獨熱編碼）\n",
    "y_train_2d_list = [[0] * num_classes for _ in range(len(y_train))]\n",
    "for i, item in enumerate(y_train):\n",
    "    y_train_2d_list[i][item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4cd44e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_train_2d_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dbf4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 ELM 參數\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 25  # 隱藏層神經元數量\n",
    "output_size = len(np.unique(y_train))  # 類別數目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "813f91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成隨機權重和偏差\n",
    "input_weights = np.random.normal(size=(input_size, hidden_size))\n",
    "biases = np.random.normal(size=(hidden_size,))\n",
    "output_weights = np.zeros((hidden_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53003477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 sigmoid 函數\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db552570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 運行 ELM 訓練\n",
    "hidden_activations = sigmoid(np.dot(X_train, input_weights) + biases)\n",
    "output_weights = np.dot(np.linalg.pinv(hidden_activations), y_train_2d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b730a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測\n",
    "hidden_activations_test = sigmoid(np.dot(X_val, input_weights) + biases)\n",
    "y_pred = np.dot(hidden_activations_test, output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "199b78b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2 11 ...  5  8  0]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57fd8999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4af49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9861644888547272\n"
     ]
    }
   ],
   "source": [
    "# 計算準確度\n",
    "accuracy = accuracy_score(val_target.numpy(), predicted_labels)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e83cc015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1 Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(val_target, predicted_labels)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ae8b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 98.6164%\n",
      "E.I: 1296/1301 \n",
      "Accuracy: 0.9961568024596464\n",
      "\n",
      "S.N: 1292/1301 \n",
      "Accuracy: 0.9930822444273636\n",
      "\n",
      "T.F: 1295/1301 \n",
      "Accuracy: 0.9953881629515757\n",
      "\n",
      "J.P: 1291/1301 \n",
      "Accuracy: 0.9923136049192929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/ELM/note.txt\", \"w\") as f:\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    correct_predictions = 0\n",
    "\n",
    "    item_count = len(predicted_labels)\n",
    "    \n",
    "    for n in range(len(predicted_labels)):\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == predicted_labels[n]:\n",
    "                mbti_labels_pre = personality\n",
    "                break\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == val_target[n]:\n",
    "                mbti_labels_tru = personality \n",
    "                break\n",
    "\n",
    "        if mbti_labels_pre == mbti_labels_tru:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        for n in range(4):\n",
    "            if n == 0:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['E/I'] += 1\n",
    "            elif n == 1:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['S/N'] += 1\n",
    "            elif n == 2:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['T/F'] += 1\n",
    "            elif n == 3:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['J/P'] += 1\n",
    "\n",
    "\n",
    "    accuracy = correct_predictions / len(predicted_labels) \n",
    "\n",
    "    #f.write(f\"del_count: {total_del_count_times}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.2f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.2f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.2f}\\n\\n\")\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy*100:.4f}%\")\n",
    "    f.write(f\"Validation Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "    \n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a48dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/JenMing/Desktop/MBTI/ELM/elm_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  # 或者可以使用pickle\n",
    "\n",
    "# 保存 ELM 模型的權重和偏差\n",
    "elm_model = {\n",
    "    'input_weights': input_weights,\n",
    "    'biases': biases,\n",
    "    'output_weights': output_weights\n",
    "}\n",
    "\n",
    "# 保存ELM模型\n",
    "model_filename = 'C:/Users/JenMing/Desktop/MBTI/ELM/elm_model.pkl'\n",
    "\n",
    "joblib.dump(elm_model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ba5815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 ELM 模型\n",
    "loaded_elm_model = joblib.load(model_filename)\n",
    "\n",
    "# 使用載入的模型進行預測\n",
    "#X_test = X_test.numpy()\n",
    "hidden_activations_test = sigmoid(np.dot(X_test, loaded_elm_model['input_weights']) + loaded_elm_model['biases'])\n",
    "y_pred = np.dot(hidden_activations_test, loaded_elm_model['output_weights'])\n",
    "predicted_labels = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef910a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76c6aea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.4639%\n",
      "E.I: 1292/1302 \n",
      "Accuracy: 0.9923195084485407\n",
      "\n",
      "S.N: 1290/1302 \n",
      "Accuracy: 0.9907834101382489\n",
      "\n",
      "T.F: 1292/1302 \n",
      "Accuracy: 0.9923195084485407\n",
      "\n",
      "J.P: 1293/1302 \n",
      "Accuracy: 0.9930875576036866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/ELM/note.txt\", \"w\") as f:\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    correct_predictions = 0\n",
    "\n",
    "    item_count = len(predicted_labels)\n",
    "    \n",
    "    for n in range(len(predicted_labels)):\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == predicted_labels[n]:\n",
    "                mbti_labels_pre = personality\n",
    "                break\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == y_test[n]:\n",
    "                mbti_labels_tru = personality \n",
    "                break\n",
    "\n",
    "        if mbti_labels_pre == mbti_labels_tru:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        for n in range(4):\n",
    "            if n == 0:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['E/I'] += 1\n",
    "            elif n == 1:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['S/N'] += 1\n",
    "            elif n == 2:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['T/F'] += 1\n",
    "            elif n == 3:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['J/P'] += 1\n",
    "\n",
    "\n",
    "    #accuracy = correct_predictions / len(predicted_labels) \n",
    "\n",
    "    #f.write(f\"del_count: {total_del_count_times}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.2f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.2f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.2f}\\n\\n\")\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy*100:.4f}%\")\n",
    "    f.write(f\"Test Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "    \n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ffda9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10501957  0.03113521  0.06603042 ...  0.03802156  0.00727338\n",
      "   0.04746361]\n",
      " [ 0.84181579  0.00311728  0.01315136 ...  0.00641402  0.00645428\n",
      "   0.00793565]\n",
      " [ 1.14392709 -0.03434104 -0.00979809 ... -0.00812583  0.00752317\n",
      "  -0.01404023]\n",
      " ...\n",
      " [ 0.02672751  0.05672022 -0.00200336 ...  0.00716682  0.01972081\n",
      "   0.02158144]\n",
      " [-0.02605363  1.04994902  0.02437874 ... -0.00729558 -0.02234383\n",
      "  -0.01253467]\n",
      " [-0.02718612  0.02073254 -0.04145333 ... -0.03295789  0.01374188\n",
      "  -0.01214026]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8b0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9883b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
