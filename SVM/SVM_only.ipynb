{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f813bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca10b8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['INFJ', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['INTP', 'INTP', 'INTP', 'ENTP', 'ENTP', 'ENTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['INTP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['INTP', 'ENTP', 'INTJ', 'INFP', 'INTJ', 'INTJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['ENTJ', 'ENTJ', 'ENTJ', 'ENTP', 'ENTJ', 'ENTJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ['INFJ', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INTP...\n",
       "1  ENTP  ['INTP', 'INTP', 'INTP', 'ENTP', 'ENTP', 'ENTP...\n",
       "2  INTP  ['INTP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP...\n",
       "3  INTJ  ['INTP', 'ENTP', 'INTJ', 'INFP', 'INTJ', 'INTJ...\n",
       "4  ENTJ  ['ENTJ', 'ENTJ', 'ENTJ', 'ENTP', 'ENTJ', 'ENTJ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/one_type_one_sentence/mbti_to_LSTM_DF.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d30fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0,\n",
    "                        'ENTP': 1,\n",
    "                        'INTP': 2,\n",
    "                        'INTJ': 3,\n",
    "                        'ENTJ': 4,\n",
    "                        'ENFJ': 5,\n",
    "                        'INFP': 6,\n",
    "                        'ENFP': 7,\n",
    "                        'ISFP': 8,\n",
    "                        'ISTP': 9,\n",
    "                        'ISFJ': 10,\n",
    "                        'ISTJ': 11,\n",
    "                        'ESTP': 12,\n",
    "                        'ESFP': 13,\n",
    "                        'ESTJ': 14,\n",
    "                        'ESFJ': 15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b626729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_counts = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0}\n",
    "    mbti_per_count = []\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    \n",
    "    for personality_id in dialogue_ids:\n",
    "        mbti_counts[personality_id] += 1\n",
    "    \n",
    "    for i in range(len(personality_mapping)):\n",
    "        mbti_per_count.append(round(mbti_counts[i]/len(dialogue_ids), 2))\n",
    "    \n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((mbti_per_count, target_personality_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5919c",
   "metadata": {},
   "source": [
    "'''\n",
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "total_count_del = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    count_del = 0\n",
    "    mbti_counts = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0}\n",
    "    mbti_per_count = []\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    new_dialogues_list = []\n",
    "    #print(dialogues_list)\n",
    "    for n in range(len(dialogues_list)):\n",
    "        counter = 0\n",
    "        for m in range(4):\n",
    "            if dialogues_list[n][m] == target_personality[m]:\n",
    "                counter += 1\n",
    "        if counter >= 3:\n",
    "            new_dialogues_list.append(dialogues_list[n])\n",
    "        else:\n",
    "            count_del += 1\n",
    "    #print(new_dialogues_list)\n",
    "    if len(new_dialogues_list) == 0:\n",
    "        dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "        count_del = 0\n",
    "    else:\n",
    "        dialogue_ids = [personality_mapping[personality] for personality in new_dialogues_list]\n",
    "    \n",
    "    \n",
    "    #print(dialogue_ids)\n",
    "    \n",
    "    for personality_id in dialogue_ids:\n",
    "        mbti_counts[personality_id] += 1\n",
    "    \n",
    "    for i in range(len(personality_mapping)):\n",
    "        mbti_per_count.append(round(mbti_counts[i]/len(dialogue_ids), 2))\n",
    "    \n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((mbti_per_count, target_personality_id))\n",
    "    \n",
    "    total_count_del += count_del\n",
    "    \n",
    "print(total_count_del)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d312e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列並轉換為張量\n",
    "input_data = torch.tensor([feature for feature, _ in encoded_data], dtype=torch.float32)\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.int64)  # 使用int64类型，因为它是类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6cc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集切分為訓練集和驗證集\n",
    "train_dialogues, X_temp, train_target, y_temp = train_test_split(input_data, target_personality, test_size=0.3, random_state=42)\n",
    "\n",
    "# 进一步划分剩余的数据为验证集和测试集\n",
    "val_dialogues, X_test, val_target, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8a478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6071\n",
      "1301\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dialogues))\n",
    "print(len(val_dialogues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca555a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6400, 0.0400, 0.0600, 0.0900, 0.0000, 0.0000, 0.1100, 0.0600, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(val_dialogues[0])\n",
    "print(val_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9385ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建反向映射\n",
    "reverse_personality_mapping = {v: k for k, v in personality_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de239d0",
   "metadata": {},
   "source": [
    "for index, personality_num in enumerate(train_target):\n",
    "    tmp_dialogues = train_dialogues[index]\n",
    "    # 找到前三大的值\n",
    "    top_three = sorted(set(tmp_dialogues), reverse=True)[:3]\n",
    "\n",
    "    # 将列表中不在前三大值中的元素设为0\n",
    "    result  = [x if x in top_three else 0 for x in tmp_dialogues]\n",
    "    \n",
    "    # 转换为PyTorch张量\n",
    "    train_dialogues[index] = torch.FloatTensor(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1553c7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6071\n"
     ]
    }
   ],
   "source": [
    "similar_tag = 1 #控制多少個指標以下要捨棄 (1~4)\n",
    "total_del_count_times = 0\n",
    "for index, personality_num in enumerate(train_target):\n",
    "    del_count_times = 0\n",
    "    # 使用反向映射将数字转换为对应的个性\n",
    "    personality = reverse_personality_mapping.get(int(personality_num), \"Unknown\")\n",
    "    tmp_dialogues = train_dialogues[index]\n",
    "    for n in range(len(personality_mapping)):\n",
    "        counter = 0\n",
    "        for m in range(4):\n",
    "            if reverse_personality_mapping[n][m] == personality[m]:\n",
    "                counter += 1\n",
    "        if counter < similar_tag:\n",
    "            train_dialogues[index][n] = 0.0\n",
    "            del_count_times += 1\n",
    "            \n",
    "    # 计算所有非零值的总和\n",
    "    non_zero_sum = torch.sum(train_dialogues[index])\n",
    "\n",
    "    #如果都是0\n",
    "    if non_zero_sum == 0: \n",
    "        train_dialogues[index] = tmp_dialogues\n",
    "    else:  # 重新分配其他非零值，使它们的总和为1\n",
    "        train_dialogues[index] = train_dialogues[index] / non_zero_sum\n",
    "        total_del_count_times += del_count_times\n",
    "\n",
    "print(total_del_count_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15069b97",
   "metadata": {},
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 创建一个SVM分类器\n",
    "svm_classifier = svm.SVC(kernel='linear', C=1)\n",
    "\n",
    "# 使用训练数据训练SVM模型\n",
    "svm_classifier.fit(train_dialogues, train_target)\n",
    "\n",
    "# 使用训练好的SVM模型进行预测\n",
    "predicted_labels = svm_classifier.predict(val_dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29eef7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳超參數配置: {'C': 0.5}\n",
      "最佳交叉驗證得分: 0.9932470966298534\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 創建一個SVM分類器\n",
    "svm_classifier = svm.SVC(kernel='rbf')\n",
    "\n",
    "# 定義超參數網格，這是一個示例，您可以根據需要擴展它\n",
    "param_grid = {'C': [0.1, 0.5]}\n",
    "\n",
    "# 使用GridSearchCV進行超參數調整\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
    "grid_search.fit(train_dialogues, train_target)\n",
    "\n",
    "# 打印最佳超參數配置和交叉驗證得分\n",
    "print(\"最佳超參數配置:\", grid_search.best_params_)\n",
    "print(\"最佳交叉驗證得分:\", grid_search.best_score_)\n",
    "\n",
    "# 使用最佳的超參數配置來訓練模型\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "best_svm_classifier.fit(train_dialogues, train_target)\n",
    "\n",
    "# 使用訓練好的SVM模型進行預測\n",
    "predicted_labels = best_svm_classifier.predict(val_dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f2dbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(val_target, predicted_labels)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb60be53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 98.4627%\n",
      "E.I: 1294/1301 \n",
      "Accuracy: 0.994619523443505\n",
      "\n",
      "S.N: 1292/1301 \n",
      "Accuracy: 0.9930822444273636\n",
      "\n",
      "T.F: 1290/1301 \n",
      "Accuracy: 0.9915449654112222\n",
      "\n",
      "J.P: 1294/1301 \n",
      "Accuracy: 0.994619523443505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/SVM/note.txt\", \"w\") as f:\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    correct_predictions = 0\n",
    "\n",
    "    item_count = len(predicted_labels)\n",
    "    \n",
    "    for n in range(len(predicted_labels)):\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == predicted_labels[n]:\n",
    "                mbti_labels_pre = personality\n",
    "                break\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == val_target[n]:\n",
    "                mbti_labels_tru = personality \n",
    "                break\n",
    "\n",
    "        if mbti_labels_pre == mbti_labels_tru:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        for n in range(4):\n",
    "            if n == 0:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['E/I'] += 1\n",
    "            elif n == 1:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['S/N'] += 1\n",
    "            elif n == 2:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['T/F'] += 1\n",
    "            elif n == 3:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['J/P'] += 1\n",
    "\n",
    "\n",
    "    accuracy = correct_predictions / len(predicted_labels) \n",
    "\n",
    "    #f.write(f\"del_count: {total_del_count_times}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.2f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.2f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.2f}\\n\\n\")\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy*100:.4f}%\")\n",
    "    f.write(f\"Validation Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "    \n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4e9304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/JenMing/Desktop/MBTI/SVM/svm_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  # 或者可以使用pickle\n",
    "\n",
    "# 保存SVM模型\n",
    "model_filename = 'C:/Users/JenMing/Desktop/MBTI/SVM/svm_model.pkl'\n",
    "joblib.dump(best_svm_classifier, model_filename)\n",
    "#joblib.dump(svm_classifier, model_filename) 沒用交叉驗證的話要改這個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f1d28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载SVM模型\n",
    "loaded_svm_model = joblib.load('C:/Users/JenMing/Desktop/MBTI/SVM/svm_model.pkl')\n",
    "\n",
    "# 使用加载的模型进行预测\n",
    "loaded_predicted_labels = loaded_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2cbcf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = loaded_predicted_labels\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79299ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.8495%\n",
      "E.I: 1299/1302 \n",
      "Accuracy: 0.9976958525345622\n",
      "\n",
      "S.N: 1289/1302 \n",
      "Accuracy: 0.9900153609831029\n",
      "\n",
      "T.F: 1284/1302 \n",
      "Accuracy: 0.9861751152073732\n",
      "\n",
      "J.P: 1290/1302 \n",
      "Accuracy: 0.9907834101382489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/SVM/note.txt\", \"w\") as f:\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    correct_predictions = 0\n",
    "\n",
    "    item_count = len(predicted_labels)\n",
    "    \n",
    "    for n in range(len(predicted_labels)):\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == predicted_labels[n]:\n",
    "                mbti_labels_pre = personality\n",
    "                break\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == y_test[n]:\n",
    "                mbti_labels_tru = personality \n",
    "                break\n",
    "\n",
    "        if mbti_labels_pre == mbti_labels_tru:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        for n in range(4):\n",
    "            if n == 0:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['E/I'] += 1\n",
    "            elif n == 1:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['S/N'] += 1\n",
    "            elif n == 2:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['T/F'] += 1\n",
    "            elif n == 3:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['J/P'] += 1\n",
    "\n",
    "\n",
    "    accuracy = correct_predictions / len(predicted_labels) \n",
    "\n",
    "    #f.write(f\"del_count: {total_del_count_times}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.2f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.2f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.2f}\\n\\n\")\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy*100:.4f}%\")\n",
    "    f.write(f\"Test Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "    \n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db8dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  0  0 ...  4  1  6]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f36e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
