{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d60a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "#from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bca95c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...\n",
       "1  ENTP  ['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...\n",
       "2  INTP  ['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...\n",
       "3  INTJ  ['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...\n",
       "4  ENTJ  ['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/LSTM/mbti_to_LSTM_DF.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9224be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0,\n",
    "                        'ENTP': 1,\n",
    "                        'INTP': 2,\n",
    "                        'INTJ': 3,\n",
    "                        'ENTJ': 4,\n",
    "                        'ENFJ': 5,\n",
    "                        'INFP': 6,\n",
    "                        'ENFP': 7,\n",
    "                        'ISFP': 8,\n",
    "                        'ISTP': 9,\n",
    "                        'ISFJ': 10,\n",
    "                        'ISTJ': 11,\n",
    "                        'ESTP': 12,\n",
    "                        'ESFP': 13,\n",
    "                        'ESTJ': 14,\n",
    "                        'ESFJ': 15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88cfc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_counts = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0}\n",
    "    mbti_per_count = []\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    \n",
    "    for personality_id in dialogue_ids:\n",
    "        mbti_counts[personality_id] += 1\n",
    "    \n",
    "    for i in range(len(personality_mapping)):\n",
    "        mbti_per_count.append(round(mbti_counts[i]/len(dialogue_ids), 2))\n",
    "    \n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((mbti_per_count, target_personality_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470306bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.16,\n",
       "  0.07,\n",
       "  0.21,\n",
       "  0.05,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3,\n",
       "  0.14,\n",
       "  0.0,\n",
       "  0.05,\n",
       "  0.0,\n",
       "  0.02,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6711bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列並轉換為張量\n",
    "input_data = torch.tensor([feature for feature, _ in encoded_data], dtype=torch.float32)\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.int64)  # 使用int64类型，因为它是类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1fd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型（修改 input_size）\n",
    "class PersonalityPredictionANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_prob=0.5):\n",
    "        super(PersonalityPredictionANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc26d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集切分為訓練集和驗證集\n",
    "train_dialogues, val_dialogues, train_target, val_target = train_test_split(input_data, target_personality, test_size=0.15, random_state=42)\n",
    "\n",
    "# 初始化模型\n",
    "hidden_size = 128\n",
    "input_size = len(personality_mapping)+1\n",
    "output_size = len(personality_mapping)\n",
    "model = PersonalityPredictionANN(input_size, hidden_size, hidden_size, output_size)\n",
    "\n",
    "# 定义損失函數和優化器 (CEL:分類問題 MSE:回归问题)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "weight_decay = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721457f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#早停\n",
    "patience = 10  # 設定早期停止的耐心值\n",
    "best_val_loss = float('inf')\n",
    "counter = 0  # 用於計算連續的驗證損失沒有改善的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377a65e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyelm in c:\\users\\jenming\\anaconda3\\lib\\site-packages (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyelm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029a0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elm(X_train, y_train, n_hidden):\n",
    "    # 随机初始化输入层到隐藏层的权重矩阵\n",
    "    input_weights = np.random.rand(X_train.shape[1], n_hidden)\n",
    "\n",
    "    # 计算隐藏层的输出\n",
    "    hidden_outputs = np.dot(X_train, input_weights)\n",
    "\n",
    "    # 计算隐藏层到输出层的权重矩阵\n",
    "    output_weights = np.linalg.pinv(hidden_outputs).dot(y_train)\n",
    "\n",
    "    return input_weights, output_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0593fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_elm(X_test, input_weights, output_weights):\n",
    "    hidden_outputs = np.dot(X_test, input_weights)\n",
    "    y_pred = np.dot(hidden_outputs, output_weights)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be6ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_weights, output_weights = train_elm(train_dialogues, train_target, 100)\n",
    "y_pred_tra = predict_elm(train_dialogues, input_weights, output_weights)\n",
    "y_pred_val = predict_elm(val_dialogues, input_weights, output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2031fceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.86954168 4.82586411 3.17827376 ... 6.44912336 4.56641184 6.04857192]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31983d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11082474226804123\n",
      "Precision: 0.0848617701493841\n",
      "Recall: 0.08161942448159668\n",
      "F1 Score: 0.04979349890753973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_train_rounded = [round(pred) for pred in y_pred_tra]\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(train_target, y_pred_train_rounded)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(train_target, y_pred_train_rounded, average='macro')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(train_target, y_pred_train_rounded, average='macro')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(train_target, y_pred_train_rounded, average='macro')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba5dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 elm_predictions 添加为特征\n",
    "\n",
    "svm_predictions_train = torch.tensor(y_pred_tra, dtype=input_data.dtype, device=input_data.device)\n",
    "\n",
    "svm_predictions_train = svm_predictions_train.view(-1, 1)\n",
    "\n",
    "new_train_dialogues = torch.cat((train_dialogues, svm_predictions_train), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "svm_predictions_val = torch.tensor(y_pred_val, dtype=input_data.dtype, device=input_data.device)\n",
    "\n",
    "svm_predictions_val = svm_predictions_val.view(-1, 1)\n",
    "\n",
    "new_val_dialogues = torch.cat((val_dialogues, svm_predictions_val), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ab5120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 2.2822\n",
      "Validation Loss: 2.1296, Validation Accuracy: 29.1091%\n",
      "Epoch [2/60], Loss: 2.1654\n",
      "Validation Loss: 2.0287, Validation Accuracy: 31.4132%\n",
      "Epoch [3/60], Loss: 2.0678\n",
      "Validation Loss: 1.9756, Validation Accuracy: 32.2581%\n",
      "Epoch [4/60], Loss: 2.0461\n",
      "Validation Loss: 1.9667, Validation Accuracy: 33.0261%\n",
      "Epoch [5/60], Loss: 2.0389\n",
      "Validation Loss: 1.9577, Validation Accuracy: 33.1797%\n",
      "Epoch [6/60], Loss: 2.0338\n",
      "Validation Loss: 1.9573, Validation Accuracy: 33.3333%\n",
      "Epoch [7/60], Loss: 2.0264\n",
      "Validation Loss: 1.9594, Validation Accuracy: 33.3333%\n",
      "Epoch [8/60], Loss: 2.0254\n",
      "Validation Loss: 1.9491, Validation Accuracy: 33.4869%\n",
      "Epoch [9/60], Loss: 2.0279\n",
      "Validation Loss: 1.9521, Validation Accuracy: 33.7174%\n",
      "Epoch [10/60], Loss: 2.0247\n",
      "Validation Loss: 1.9484, Validation Accuracy: 33.6406%\n",
      "Epoch [11/60], Loss: 2.0221\n",
      "Validation Loss: 1.9500, Validation Accuracy: 33.5637%\n",
      "Epoch [12/60], Loss: 2.0260\n",
      "Validation Loss: 1.9544, Validation Accuracy: 33.7174%\n",
      "Epoch [13/60], Loss: 2.0200\n",
      "Validation Loss: 1.9557, Validation Accuracy: 33.8710%\n",
      "Epoch [14/60], Loss: 2.0245\n",
      "Validation Loss: 1.9502, Validation Accuracy: 33.7174%\n",
      "Epoch [15/60], Loss: 2.0208\n",
      "Validation Loss: 1.9499, Validation Accuracy: 33.7942%\n",
      "Epoch [16/60], Loss: 2.0229\n",
      "Validation Loss: 1.9451, Validation Accuracy: 33.8710%\n",
      "Epoch [17/60], Loss: 2.0202\n",
      "Validation Loss: 1.9484, Validation Accuracy: 33.7942%\n",
      "Epoch [18/60], Loss: 2.0218\n",
      "Validation Loss: 1.9488, Validation Accuracy: 33.8710%\n",
      "Epoch [19/60], Loss: 2.0149\n",
      "Validation Loss: 1.9486, Validation Accuracy: 33.7174%\n",
      "Epoch [20/60], Loss: 2.0182\n",
      "Validation Loss: 1.9534, Validation Accuracy: 34.3318%\n",
      "Epoch [21/60], Loss: 2.0194\n",
      "Validation Loss: 1.9549, Validation Accuracy: 33.9478%\n",
      "Epoch [22/60], Loss: 2.0168\n",
      "Validation Loss: 1.9475, Validation Accuracy: 33.4869%\n",
      "Epoch [23/60], Loss: 2.0166\n",
      "Validation Loss: 1.9453, Validation Accuracy: 34.0246%\n",
      "Epoch [24/60], Loss: 2.0125\n",
      "Validation Loss: 1.9472, Validation Accuracy: 33.8710%\n",
      "Epoch [25/60], Loss: 2.0167\n",
      "Validation Loss: 1.9495, Validation Accuracy: 33.8710%\n",
      "Epoch [26/60], Loss: 2.0142\n",
      "Validation Loss: 1.9470, Validation Accuracy: 34.0246%\n",
      "Early Stopping: Validation loss has not improved for 10 epochs. Stopping training.\n",
      "E.I: 26405/33852 \n",
      "Accuracy: 0.7800129977549333\n",
      "\n",
      "S.N: 29614/33852 \n",
      "Accuracy: 0.8748079877112135\n",
      "\n",
      "T.F: 25353/33852 \n",
      "Accuracy: 0.7489365473236441\n",
      "\n",
      "J.P: 21012/33852 \n",
      "Accuracy: 0.6207018787663949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/ANN/Model/pr/ELM/note.txt\", \"w\") as f:\n",
    "    num_epochs = 60\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    item_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 將模型設置為訓練模式\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for dialogue_batch, target_batch in zip(new_train_dialogues, train_target):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(dialogue_batch)\n",
    "            loss = criterion(outputs, target_batch.long())  # 使用交叉熵損失\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(new_train_dialogues)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "        f.write(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\\n\")\n",
    "        \n",
    "        # 驗證模型\n",
    "        model.eval()  # 將模型設置為評估模式\n",
    "        correct_predictions = 0\n",
    "        total_samples = len(new_val_dialogues)\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for dialogue_batch, target_batch in zip(new_val_dialogues, val_target):\n",
    "                outputs = model(dialogue_batch)\n",
    "                loss = criterion(outputs, target_batch.long())  # 使用交叉熵損失\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted_class = torch.argmax(outputs).item()\n",
    "                true_class = target_batch.item()\n",
    "\n",
    "                for personality, value in personality_mapping.items():\n",
    "                    if value == predicted_class:\n",
    "                        mbti_labels_pre = personality\n",
    "                        break\n",
    "                for personality, value in personality_mapping.items():\n",
    "                    if value == int(true_class):\n",
    "                        mbti_labels_tru = personality \n",
    "                        break\n",
    "\n",
    "                for n in range(4):\n",
    "                    if n == 0:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['E/I'] += 1\n",
    "                    elif n == 1:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['S/N'] += 1\n",
    "                    elif n == 2:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['T/F'] += 1\n",
    "                    elif n == 3:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['J/P'] += 1\n",
    "\n",
    "                if predicted_class == true_class:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "        item_count += total_samples\n",
    "        average_val_loss = val_loss / len(val_dialogues)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {accuracy*100:.4f}%\")\n",
    "        f.write(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "        \n",
    "        # 檢查驗證損失是否改善\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        # 如果連續一定次數（耐心值）驗證損失沒有改善，則停止訓練\n",
    "        if counter >= patience:\n",
    "            print(f\"Early Stopping: Validation loss has not improved for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba6e840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/JenMing/Desktop/MBTI/ANN/Model/pr/ELM/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a314ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
