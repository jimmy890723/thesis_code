{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5661a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "#from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da82d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...\n",
       "1  ENTP  ['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...\n",
       "2  INTP  ['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...\n",
       "3  INTJ  ['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...\n",
       "4  ENTJ  ['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/LSTM/mbti_to_LSTM_DF.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a4d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0,\n",
    "                        'ENTP': 1,\n",
    "                        'INTP': 2,\n",
    "                        'INTJ': 3,\n",
    "                        'ENTJ': 4,\n",
    "                        'ENFJ': 5,\n",
    "                        'INFP': 6,\n",
    "                        'ENFP': 7,\n",
    "                        'ISFP': 8,\n",
    "                        'ISTP': 9,\n",
    "                        'ISFJ': 10,\n",
    "                        'ISTJ': 11,\n",
    "                        'ESTP': 12,\n",
    "                        'ESFP': 13,\n",
    "                        'ESTJ': 14,\n",
    "                        'ESFJ': 15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e3e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_counts = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0}\n",
    "    mbti_per_count = []\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    \n",
    "    for personality_id in dialogue_ids:\n",
    "        mbti_counts[personality_id] += 1\n",
    "    \n",
    "    for i in range(len(personality_mapping)):\n",
    "        mbti_per_count.append(round(mbti_counts[i]/len(dialogue_ids), 2))\n",
    "    \n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((mbti_per_count, target_personality_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88044e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.16,\n",
       "  0.07,\n",
       "  0.21,\n",
       "  0.05,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3,\n",
       "  0.14,\n",
       "  0.0,\n",
       "  0.05,\n",
       "  0.0,\n",
       "  0.02,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24393357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列並轉換為張量\n",
    "input_data = torch.tensor([feature for feature, _ in encoded_data], dtype=torch.float32)\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.int64)  # 使用int64类型，因为它是类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eeb482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型（修改 input_size）\n",
    "class PersonalityPredictionANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_prob=0.5):\n",
    "        super(PersonalityPredictionANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac35fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集切分為訓練集和驗證集\n",
    "train_dialogues, val_dialogues, train_target, val_target = train_test_split(input_data, target_personality, test_size=0.15, random_state=42)\n",
    "\n",
    "# 初始化模型\n",
    "hidden_size = 128\n",
    "input_size = len(personality_mapping)+1\n",
    "output_size = len(personality_mapping)\n",
    "model = PersonalityPredictionANN(input_size, hidden_size, hidden_size, output_size)\n",
    "\n",
    "# 定义損失函數和優化器 (CEL:分類問題 MSE:回归问题)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "weight_decay = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc3f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#早停\n",
    "patience = 10  # 設定早期停止的耐心值\n",
    "best_val_loss = float('inf')\n",
    "counter = 0  # 用於計算連續的驗證損失沒有改善的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4ce93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# 创建一个SVM分类器\n",
    "svm_classifier = svm.SVC(kernel='linear', C=1.0)\n",
    "#svm_classifier = svm.SVC(kernel='rbf', C=0.5)\n",
    "\n",
    "# 使用训练数据训练SVM模型\n",
    "svm_classifier.fit(train_dialogues, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4898802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42242703533026116\n",
      "0.1832975879173075\n",
      "0.17594679630761842\n",
      "0.1667535413734707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 计算预测值\n",
    "svm_predictions = svm_classifier.predict(val_dialogues)\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = metrics.accuracy_score(val_target, svm_predictions)\n",
    "print(accuracy)\n",
    "\n",
    "# 计算精确度\n",
    "precision = metrics.precision_score(val_target, svm_predictions, average='macro')\n",
    "print(precision)\n",
    "\n",
    "# 计算召回率\n",
    "recall = metrics.recall_score(val_target, svm_predictions, average='macro')\n",
    "print(recall)\n",
    "\n",
    "# 计算F1分数\n",
    "f1_score = metrics.f1_score(val_target, svm_predictions, average='macro')\n",
    "print(f1_score)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "confusion_matrix = metrics.confusion_matrix(val_target, svm_predictions)\n",
    "\n",
    "# 计算AUC\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(val_target, svm_predictions)\n",
    "#auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bff5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7372,)\n",
      "torch.Size([7372, 1])\n",
      "torch.Size([7372, 16])\n"
     ]
    }
   ],
   "source": [
    "# train_data\n",
    "# 使用SVM模型进行预测\n",
    "svm_predictions_train = svm_classifier.predict(train_dialogues)\n",
    "\n",
    "# 假设 svm_predictions 是一个NumPy数组\n",
    "svm_predictions_train = svm_predictions_train.astype(np.float32)\n",
    "\n",
    "print(svm_predictions_train.shape)\n",
    "\n",
    "svm_predictions_train = torch.tensor(svm_predictions_train, dtype=input_data.dtype, device=input_data.device)\n",
    "\n",
    "svm_predictions_train = svm_predictions_train.view(-1, 1)\n",
    "\n",
    "print(svm_predictions_train.shape)\n",
    "print(train_dialogues.shape)\n",
    "# 将 svm_predictions 添加为特征\n",
    "new_train_dialogues = torch.cat((train_dialogues, svm_predictions_train), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb4a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302,)\n",
      "torch.Size([1302, 1])\n",
      "torch.Size([1302, 16])\n"
     ]
    }
   ],
   "source": [
    "# validation_data\n",
    "# 使用SVM模型进行预测\n",
    "svm_predictions_val = svm_classifier.predict(val_dialogues)\n",
    "\n",
    "# 假设 svm_predictions 是一个NumPy数组\n",
    "svm_predictions_val = svm_predictions_val.astype(np.float32)\n",
    "\n",
    "print(svm_predictions_val.shape)\n",
    "\n",
    "svm_predictions_val = torch.tensor(svm_predictions_val, dtype=input_data.dtype, device=input_data.device)\n",
    "\n",
    "svm_predictions_val = svm_predictions_val.view(-1, 1)\n",
    "\n",
    "print(svm_predictions_val.shape)\n",
    "print(val_dialogues.shape)\n",
    "# 将 svm_predictions 添加为特征\n",
    "new_val_dialogues = torch.cat((val_dialogues, svm_predictions_val), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d07841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 2.1980\n",
      "Validation Loss: 2.0613, Validation Accuracy: 37.5576%\n",
      "Epoch [2/60], Loss: 2.1105\n",
      "Validation Loss: 2.0325, Validation Accuracy: 37.5576%\n",
      "Epoch [3/60], Loss: 2.0951\n",
      "Validation Loss: 2.0168, Validation Accuracy: 37.5576%\n",
      "Epoch [4/60], Loss: 2.0762\n",
      "Validation Loss: 1.9980, Validation Accuracy: 37.5576%\n",
      "Epoch [5/60], Loss: 2.0603\n",
      "Validation Loss: 1.9760, Validation Accuracy: 37.5576%\n",
      "Epoch [6/60], Loss: 2.0399\n",
      "Validation Loss: 1.9706, Validation Accuracy: 38.2488%\n",
      "Epoch [7/60], Loss: 2.0270\n",
      "Validation Loss: 1.9517, Validation Accuracy: 38.7097%\n",
      "Epoch [8/60], Loss: 2.0199\n",
      "Validation Loss: 1.9423, Validation Accuracy: 38.4025%\n",
      "Epoch [9/60], Loss: 2.0136\n",
      "Validation Loss: 1.9426, Validation Accuracy: 38.1720%\n",
      "Epoch [10/60], Loss: 2.0125\n",
      "Validation Loss: 1.9413, Validation Accuracy: 38.7865%\n",
      "Epoch [11/60], Loss: 2.0127\n",
      "Validation Loss: 1.9435, Validation Accuracy: 38.5561%\n",
      "Epoch [12/60], Loss: 2.0077\n",
      "Validation Loss: 1.9376, Validation Accuracy: 38.3257%\n",
      "Epoch [13/60], Loss: 2.0106\n",
      "Validation Loss: 1.9404, Validation Accuracy: 38.5561%\n",
      "Epoch [14/60], Loss: 2.0111\n",
      "Validation Loss: 1.9374, Validation Accuracy: 38.6329%\n",
      "Epoch [15/60], Loss: 2.0092\n",
      "Validation Loss: 1.9333, Validation Accuracy: 38.4025%\n",
      "Epoch [16/60], Loss: 2.0062\n",
      "Validation Loss: 1.9393, Validation Accuracy: 38.5561%\n",
      "Epoch [17/60], Loss: 2.0061\n",
      "Validation Loss: 1.9364, Validation Accuracy: 38.7865%\n",
      "Epoch [18/60], Loss: 2.0060\n",
      "Validation Loss: 1.9330, Validation Accuracy: 38.8633%\n",
      "Epoch [19/60], Loss: 2.0029\n",
      "Validation Loss: 1.9297, Validation Accuracy: 38.9401%\n",
      "Epoch [20/60], Loss: 2.0045\n",
      "Validation Loss: 1.9390, Validation Accuracy: 38.7865%\n",
      "Epoch [21/60], Loss: 2.0030\n",
      "Validation Loss: 1.9388, Validation Accuracy: 38.7097%\n",
      "Epoch [22/60], Loss: 2.0061\n",
      "Validation Loss: 1.9382, Validation Accuracy: 38.8633%\n",
      "Epoch [23/60], Loss: 2.0061\n",
      "Validation Loss: 1.9364, Validation Accuracy: 38.7865%\n",
      "Epoch [24/60], Loss: 2.0031\n",
      "Validation Loss: 1.9328, Validation Accuracy: 38.7097%\n",
      "Epoch [25/60], Loss: 2.0092\n",
      "Validation Loss: 1.9355, Validation Accuracy: 38.8633%\n",
      "Epoch [26/60], Loss: 2.0033\n",
      "Validation Loss: 1.9330, Validation Accuracy: 38.8633%\n",
      "Epoch [27/60], Loss: 2.0043\n",
      "Validation Loss: 1.9320, Validation Accuracy: 38.7097%\n",
      "Epoch [28/60], Loss: 2.0018\n",
      "Validation Loss: 1.9250, Validation Accuracy: 38.7865%\n",
      "Epoch [29/60], Loss: 2.0020\n",
      "Validation Loss: 1.9335, Validation Accuracy: 38.6329%\n",
      "Epoch [30/60], Loss: 2.0009\n",
      "Validation Loss: 1.9284, Validation Accuracy: 38.7865%\n",
      "Epoch [31/60], Loss: 1.9976\n",
      "Validation Loss: 1.9305, Validation Accuracy: 38.7097%\n",
      "Epoch [32/60], Loss: 2.0037\n",
      "Validation Loss: 1.9322, Validation Accuracy: 38.6329%\n",
      "Epoch [33/60], Loss: 2.0006\n",
      "Validation Loss: 1.9333, Validation Accuracy: 38.8633%\n",
      "Epoch [34/60], Loss: 2.0016\n",
      "Validation Loss: 1.9331, Validation Accuracy: 38.5561%\n",
      "Epoch [35/60], Loss: 2.0018\n",
      "Validation Loss: 1.9277, Validation Accuracy: 38.5561%\n",
      "Epoch [36/60], Loss: 1.9964\n",
      "Validation Loss: 1.9302, Validation Accuracy: 38.7865%\n",
      "Epoch [37/60], Loss: 2.0001\n",
      "Validation Loss: 1.9314, Validation Accuracy: 38.5561%\n",
      "Epoch [38/60], Loss: 1.9966\n",
      "Validation Loss: 1.9284, Validation Accuracy: 38.9401%\n",
      "Early Stopping: Validation loss has not improved for 10 epochs. Stopping training.\n",
      "E.I: 39028/49476 \n",
      "Accuracy: 0.7888269059746139\n",
      "\n",
      "S.N: 43282/49476 \n",
      "Accuracy: 0.8748079877112135\n",
      "\n",
      "T.F: 38868/49476 \n",
      "Accuracy: 0.7855930147950522\n",
      "\n",
      "J.P: 32686/49476 \n",
      "Accuracy: 0.6606435443447328\n",
      "\n",
      "Accuracy: 0.38521707494542806\n",
      "Precision: 0.2773895758630573\n",
      "Recall: 0.38521707494542806\n",
      "F1 Score: 0.3058105782812862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/ANN/Model/pr/note.txt\", \"w\") as f:\n",
    "    num_epochs = 60\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    item_count = 0\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 將模型設置為訓練模式\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for dialogue_batch, target_batch in zip(new_train_dialogues, train_target):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(dialogue_batch)\n",
    "            loss = criterion(outputs, target_batch.long())  # 使用交叉熵損失\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(new_train_dialogues)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "        f.write(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\\n\")\n",
    "        \n",
    "        # 驗證模型\n",
    "        model.eval()  # 將模型設置為評估模式\n",
    "        correct_predictions = 0\n",
    "        total_samples = len(new_val_dialogues)\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for dialogue_batch, target_batch in zip(new_val_dialogues, val_target):\n",
    "                outputs = model(dialogue_batch)\n",
    "                loss = criterion(outputs, target_batch.long())  # 使用交叉熵損失\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted_class = torch.argmax(outputs).item()\n",
    "                true_class = target_batch.item()\n",
    "                \n",
    "                predictions.append(predicted_class)\n",
    "                labels.append(true_class)  \n",
    "                \n",
    "                for personality, value in personality_mapping.items():\n",
    "                    if value == predicted_class:\n",
    "                        mbti_labels_pre = personality\n",
    "                        break\n",
    "                for personality, value in personality_mapping.items():\n",
    "                    if value == int(true_class):\n",
    "                        mbti_labels_tru = personality \n",
    "                        break\n",
    "\n",
    "                for n in range(4):\n",
    "                    if n == 0:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['E/I'] += 1\n",
    "                    elif n == 1:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['S/N'] += 1\n",
    "                    elif n == 2:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['T/F'] += 1\n",
    "                    elif n == 3:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['J/P'] += 1\n",
    "\n",
    "                if predicted_class == true_class:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "        item_count += total_samples\n",
    "        average_val_loss = val_loss / len(val_dialogues)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {accuracy*100:.4f}%\")\n",
    "        f.write(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "        \n",
    "        # 檢查驗證損失是否改善\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        # 如果連續一定次數（耐心值）驗證損失沒有改善，則停止訓練\n",
    "        if counter >= patience:\n",
    "            print(f\"Early Stopping: Validation loss has not improved for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='weighted')  # 可以使用 'micro'、'macro' 或 'weighted'\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    \n",
    "    f.write(f'Accuracy: {accuracy}\\n')\n",
    "    f.write(f'Precision: {precision}\\n')\n",
    "    f.write(f'Recall: {recall}\\n')\n",
    "    f.write(f'F1 Score: {f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d091185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/JenMing/Desktop/MBTI/ANN/Model/pr/best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
