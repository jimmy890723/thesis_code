{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4ad6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76911874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...\n",
       "1  ENTP  ['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...\n",
       "2  INTP  ['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...\n",
       "3  INTJ  ['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...\n",
       "4  ENTJ  ['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/LSTM/mbti_to_LSTM_DF.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9eb2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0,\n",
    "                        'ENTP': 1,\n",
    "                        'INTP': 2,\n",
    "                        'INTJ': 3,\n",
    "                        'ENTJ': 4,\n",
    "                        'ENFJ': 5,\n",
    "                        'INFP': 6,\n",
    "                        'ENFP': 7,\n",
    "                        'ISFP': 8,\n",
    "                        'ISTP': 9,\n",
    "                        'ISFJ': 10,\n",
    "                        'ISTJ': 11,\n",
    "                        'ESTP': 12,\n",
    "                        'ESFP': 13,\n",
    "                        'ESTJ': 14,\n",
    "                        'ESFJ': 15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4d95a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((dialogue_ids, target_personality_id))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029219fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 動態計算 input_size\n",
    "max_dialogue_length = max(len(dialogue) for dialogue, _ in encoded_data)\n",
    "input_size = max_dialogue_length\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce17367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列並轉換為張量\n",
    "padded_dialogues = [torch.tensor(dialogue, dtype=torch.float32) for dialogue, _ in encoded_data]\n",
    "padded_dialogues = pad_sequence(padded_dialogues, batch_first=True)\n",
    "\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036ef25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 RNN 模型\n",
    "class PersonalityPredictionRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,dropout_prob=0.5):\n",
    "        super(PersonalityPredictionRNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)  # 添加全連接層\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        #self.relu = nn.ReLU()  # 添加 ReLU 激活函數\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "        #單向\n",
    "        #self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        #雙向\n",
    "        #self.fc = nn.Linear(hidden_size, output_size)\n",
    "        #self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True,  bidirectional=True)\n",
    "        #self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(\"Input shape:\", x.shape)  # 檢查輸入張量的形狀\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out.unsqueeze(1)\n",
    "        out = out[:, -1, :]  # 只取最後一個時間步的輸出\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        #out = self.relu(out) #relu\n",
    "        out = F.sigmoid(out) #sigmoid\n",
    "        #out = F.tanh(out) #Tanh\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        #out, _ = self.rnn(x)\n",
    "        #out = out.unsqueeze(1)\n",
    "        #out = self.fc(out[:, -1, :])  # 將 out 張量轉為 3 維再進行索引\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42b548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集切分為訓練集和驗證集\n",
    "train_dialogues, val_dialogues, train_target, val_target = train_test_split(padded_dialogues, target_personality, test_size=0.15, random_state=42)\n",
    "\n",
    "# 初始化模型\n",
    "hidden_size = 256\n",
    "output_size = len(personality_mapping)\n",
    "model = PersonalityPredictionRNN(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d49550",
   "metadata": {},
   "source": [
    "# 使用SMOTE生成合成样本\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)  # 可以调整sampling_strategy来控制合成样本的数量\n",
    "train_dialogues_resampled, train_target_resampled = smote.fit_resample(train_dialogues, train_target)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "train_dialogues_resampled = torch.tensor(train_dialogues_resampled, dtype=torch.float32)\n",
    "train_target_resampled = torch.tensor(train_target_resampled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd40270",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 计算SMOTE之前的类别分布\n",
    "class_distribution_before = Counter(train_target)\n",
    "\n",
    "# 提取类别标签和对应的样本数量\n",
    "labels_before = list(class_distribution_before.keys())\n",
    "counts_before = list(class_distribution_before.values())\n",
    "\n",
    "# 绘制柱状图显示SMOTE之前的类别分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels_before, counts_before, label='Before SMOTE', alpha=0.5, color='b', width=0.4)\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Sample Count')\n",
    "plt.title('Class Distribution Before SMOTE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 计算SMOTE之后的类别分布\n",
    "class_distribution_after = Counter(train_target_resampled)\n",
    "\n",
    "# 提取类别标签和对应的样本数量\n",
    "labels_after = list(class_distribution_after.keys())\n",
    "counts_after = list(class_distribution_after.values())\n",
    "\n",
    "# 绘制柱状图显示SMOTE之后的类别分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels_after, counts_after, label='After SMOTE', alpha=0.5, color='g', width=0.4)\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Sample Count')\n",
    "plt.title('Class Distribution After SMOTE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd791deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義損失函數和優化器 (CEL:分類問題 MSE:回归问题)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss() \n",
    "weight_decay = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05, weight_decay=weight_decay)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#StepLR 调度器会每隔 step_size 个周期将学习率乘以 gamma，以逐步降低学习率\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30272265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping 相關設定\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience = 10\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e471308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/JenMing/Desktop/MBTI/LSTM/Model/note.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a10bddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 6.6204\n",
      "\n",
      "Validation Loss: 5.2876\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [2/60], Loss: 6.5135\n",
      "\n",
      "Validation Loss: 3.6621\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [3/60], Loss: 6.6933\n",
      "\n",
      "Validation Loss: 4.7401\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [4/60], Loss: 6.6276\n",
      "\n",
      "Validation Loss: 8.0194\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [5/60], Loss: 6.6293\n",
      "\n",
      "Validation Loss: 4.9349\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [6/60], Loss: 6.3833\n",
      "\n",
      "Validation Loss: 3.9702\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [7/60], Loss: 6.6979\n",
      "\n",
      "Validation Loss: 3.9356\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [8/60], Loss: 6.2403\n",
      "\n",
      "Validation Loss: 4.2307\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [9/60], Loss: 6.4333\n",
      "\n",
      "Validation Loss: 4.6552\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [10/60], Loss: 6.5033\n",
      "\n",
      "Validation Loss: 4.1540\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [11/60], Loss: 2.9487\n",
      "\n",
      "Validation Loss: 2.3950\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [12/60], Loss: 2.5364\n",
      "\n",
      "Validation Loss: 2.2908\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [13/60], Loss: 2.5541\n",
      "\n",
      "Validation Loss: 2.3475\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [14/60], Loss: 2.5611\n",
      "\n",
      "Validation Loss: 2.4049\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [15/60], Loss: 2.5652\n",
      "\n",
      "Validation Loss: 2.3553\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [16/60], Loss: 2.5843\n",
      "\n",
      "Validation Loss: 2.4560\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [17/60], Loss: 2.5483\n",
      "\n",
      "Validation Loss: 2.4051\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [18/60], Loss: 2.5859\n",
      "\n",
      "Validation Loss: 2.3458\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [19/60], Loss: 2.5710\n",
      "\n",
      "Validation Loss: 2.3242\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [20/60], Loss: 2.5727\n",
      "\n",
      "Validation Loss: 2.4667\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [21/60], Loss: 2.3825\n",
      "\n",
      "Validation Loss: 2.2414\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [22/60], Loss: 2.3148\n",
      "\n",
      "Validation Loss: 2.2314\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [23/60], Loss: 2.2942\n",
      "\n",
      "Validation Loss: 2.2104\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [24/60], Loss: 2.2839\n",
      "\n",
      "Validation Loss: 2.2126\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [25/60], Loss: 2.2755\n",
      "\n",
      "Validation Loss: 2.2053\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [26/60], Loss: 2.2750\n",
      "\n",
      "Validation Loss: 2.2002\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [27/60], Loss: 2.2604\n",
      "\n",
      "Validation Loss: 2.1967\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [28/60], Loss: 2.2608\n",
      "\n",
      "Validation Loss: 2.1930\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [29/60], Loss: 2.2509\n",
      "\n",
      "Validation Loss: 2.2006\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [30/60], Loss: 2.2507\n",
      "\n",
      "Validation Loss: 2.1974\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [31/60], Loss: 2.2205\n",
      "\n",
      "Validation Loss: 2.1805\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [32/60], Loss: 2.2045\n",
      "\n",
      "Validation Loss: 2.1761\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [33/60], Loss: 2.2056\n",
      "\n",
      "Validation Loss: 2.1731\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [34/60], Loss: 2.2023\n",
      "\n",
      "Validation Loss: 2.1750\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [35/60], Loss: 2.1964\n",
      "\n",
      "Validation Loss: 2.1730\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [36/60], Loss: 2.1961\n",
      "\n",
      "Validation Loss: 2.1704\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [37/60], Loss: 2.1968\n",
      "\n",
      "Validation Loss: 2.1698\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [38/60], Loss: 2.1930\n",
      "\n",
      "Validation Loss: 2.1694\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [39/60], Loss: 2.1924\n",
      "\n",
      "Validation Loss: 2.1709\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [40/60], Loss: 2.1899\n",
      "\n",
      "Validation Loss: 2.1684\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [41/60], Loss: 2.1860\n",
      "\n",
      "Validation Loss: 2.1655\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [42/60], Loss: 2.1829\n",
      "\n",
      "Validation Loss: 2.1648\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [43/60], Loss: 2.1836\n",
      "\n",
      "Validation Loss: 2.1649\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [44/60], Loss: 2.1845\n",
      "\n",
      "Validation Loss: 2.1643\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [45/60], Loss: 2.1826\n",
      "\n",
      "Validation Loss: 2.1642\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [46/60], Loss: 2.1821\n",
      "\n",
      "Validation Loss: 2.1645\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [47/60], Loss: 2.1820\n",
      "\n",
      "Validation Loss: 2.1644\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [48/60], Loss: 2.1855\n",
      "\n",
      "Validation Loss: 2.1639\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [49/60], Loss: 2.1803\n",
      "\n",
      "Validation Loss: 2.1638\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [50/60], Loss: 2.1794\n",
      "\n",
      "Validation Loss: 2.1635\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [51/60], Loss: 2.1801\n",
      "\n",
      "Validation Loss: 2.1639\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [52/60], Loss: 2.1813\n",
      "\n",
      "Validation Loss: 2.1639\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [53/60], Loss: 2.1807\n",
      "\n",
      "Validation Loss: 2.1640\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [54/60], Loss: 2.1770\n",
      "\n",
      "Validation Loss: 2.1640\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [55/60], Loss: 2.1800\n",
      "\n",
      "Validation Loss: 2.1640\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/60], Loss: 2.1837\n",
      "\n",
      "Validation Loss: 2.1639\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [57/60], Loss: 2.1790\n",
      "\n",
      "Validation Loss: 2.1640\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [58/60], Loss: 2.1807\n",
      "\n",
      "Validation Loss: 2.1640\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [59/60], Loss: 2.1796\n",
      "\n",
      "Validation Loss: 2.1639\n",
      "\n",
      "Shape of train_dialogues: torch.Size([7372, 57])\n",
      "Shape of val_dialogues: torch.Size([1302, 57])\n",
      "Epoch [60/60], Loss: 2.1807\n",
      "\n",
      "Validation Loss: 2.1638\n",
      "\n",
      "Early Stopping: Validation loss has not improved for 10 epochs. Stopping training.\n",
      "E.I: 60695/78120 \n",
      "Accuracy: 0.7769457245263697\n",
      "\n",
      "S.N: 67363/78120 \n",
      "Accuracy: 0.8623015873015873\n",
      "\n",
      "T.F: 44326/78120 \n",
      "Accuracy: 0.5674091141833078\n",
      "\n",
      "J.P: 43099/78120 \n",
      "Accuracy: 0.5517025089605735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "with open(file_path, \"w\") as f:\n",
    "    num_epochs = 60\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    item_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # 在每個訓練循環中檢查 train_dialogues 張量的形狀\n",
    "        print(\"Shape of train_dialogues:\", train_dialogues.shape)\n",
    "        f.write(\"Shape of train_dialogues: {}\\n\".format(train_dialogues.shape))\n",
    "        # 在每個驗證循環中檢查 val_dialogues 張量的形狀\n",
    "        print(\"Shape of val_dialogues:\", val_dialogues.shape)\n",
    "        f.write(\"Shape of val_dialogues: {}\\n\".format(val_dialogues.shape))\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for dialogue_batch, target_batch in zip(train_dialogues, train_target):\n",
    "            target_batch = target_batch.to(torch.long)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(dialogue_batch.unsqueeze(0))\n",
    "            loss = criterion(outputs.squeeze(0), target_batch)\n",
    "            \n",
    "            # 添加 L2 正则化项到损失\n",
    "            l2_loss = sum(p.norm(2) for p in model.parameters())\n",
    "            loss += weight_decay * l2_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  # 调整学习率\n",
    "        \n",
    "        average_loss = total_loss / len(train_dialogues)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\\n\")\n",
    "        f.write(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\\n\")\n",
    "        # 驗證模型\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for dialogue_batch, target_batch in zip(val_dialogues, val_target):\n",
    "                target_batch = target_batch.to(torch.long)\n",
    "                outputs = model(dialogue_batch.unsqueeze(0))\n",
    "                loss = criterion(outputs.squeeze(1), target_batch.unsqueeze(0))\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                predicted_personality_ids = outputs.argmax(dim=1)\n",
    "                predicted_personalities = [personality for personality, id in personality_mapping.items() if id in predicted_personality_ids]\n",
    "                true_personality_id = target_batch.item()\n",
    "                true_personality = [personality for personality, id in personality_mapping.items() if id == true_personality_id][0]\n",
    "                \n",
    "                #print(predicted_personalities[0])\n",
    "                #print(true_personality)\n",
    "                for n in range(4):\n",
    "                    if n == 0:\n",
    "                        if predicted_personalities[0][n] == true_personality[n]:\n",
    "                            dimension_counts['E/I'] += 1\n",
    "                    elif n == 1:\n",
    "                        if predicted_personalities[0][n] == true_personality[n]:\n",
    "                            dimension_counts['S/N'] += 1\n",
    "                    elif n == 2:\n",
    "                        if predicted_personalities[0][n] == true_personality[n]:\n",
    "                            dimension_counts['T/F'] += 1\n",
    "                    elif n == 3:\n",
    "                        if predicted_personalities[0][n] == true_personality[n]:\n",
    "                            dimension_counts['J/P'] += 1\n",
    "                item_count += 1\n",
    "                \n",
    "        average_val_loss = val_loss / len(val_dialogues)\n",
    "        print(f\"Validation Loss: {average_val_loss:.4f}\\n\")\n",
    "        f.write(f\"Validation Loss: {average_val_loss:.4f}\\n\")\n",
    "        \n",
    "        #scheduler.step(average_val_loss)\n",
    "        # 比較驗證損失，並根據需要保存最佳模型\n",
    "        \n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early Stopping: Validation loss has not improved for {} epochs. Stopping training.\".format(patience))\n",
    "                break\n",
    "        \n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    '''\n",
    "    # 計算整體準確率和各維度的準確率\n",
    "    total_correct = sum([counts['correct'] for counts in dimension_counts.values()])\n",
    "    total_total = sum([counts['total'] for counts in dimension_counts.values()])\n",
    "    overall_accuracy = total_correct / total_total if total_total > 0 else 0.0\n",
    "    \n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy:.4f}\\n\")\n",
    "    \n",
    "    for dimension, counts in dimension_counts.items():\n",
    "        dimension_accuracy = counts['correct'] / counts['total'] if counts['total'] > 0 else 0.0\n",
    "        print(f\"{dimension} Accuracy: {dimension_accuracy:.4f}\")\n",
    "        f.write(f\"{dimension} Accuracy: {dimension_accuracy:.4f}\\n\")\n",
    "    '''    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8735e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_state:\n",
    "    torch.save(best_model_state, \"C:/Users/JenMing/Desktop/MBTI/LSTM/Model/best_model.pth\")\n",
    "else:\n",
    "    torch.save(model.state_dict(), \"C:/Users/JenMing/Desktop/MBTI/LSTM/Model/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9e60ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 25.58%\n"
     ]
    }
   ],
   "source": [
    "# 加載已經訓練好的模型\n",
    "best_model = PersonalityPredictionRNN(input_size, hidden_size, output_size)\n",
    "best_model.load_state_dict(torch.load(\"C:/Users/JenMing/Desktop/MBTI/LSTM/Model/best_model.pth\"))\n",
    "best_model.eval()\n",
    "\n",
    "# 將驗證數據轉換為張量並進行預測\n",
    "with torch.no_grad():\n",
    "    val_outputs = best_model(val_dialogues)\n",
    "    predicted_personality_ids = val_outputs.argmax(dim=1)\n",
    "\n",
    "# 計算準確率\n",
    "correct_predictions = (predicted_personality_ids == val_target).sum().item()\n",
    "total_samples = val_dialogues.shape[0]\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(\"Validation Accuracy: {:.2%}\".format(accuracy))\n",
    "with open(file_path, \"a\") as f:\n",
    "    f.write(\"\\n------------\\n\")\n",
    "    f.write(\"Validation Accuracy: {:.2%}\".format(accuracy) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2713cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2557603686635945\n",
      "Precision: 0.12539515217807018\n",
      "Recall: 0.2557603686635945\n",
      "F1 Score: 0.14557502255200347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 假設 predictions 和 labels 是你的預測和實際標籤\n",
    "#cm = confusion_matrix(labels, predictions)\n",
    "accuracy = accuracy_score(val_target, predicted_personality_ids)\n",
    "precision = precision_score(val_target, predicted_personality_ids, average='weighted')  # 可以使用 'micro'、'macro' 或 'weighted'\n",
    "recall = recall_score(val_target, predicted_personality_ids, average='weighted')\n",
    "f1 = f1_score(val_target, predicted_personality_ids, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將測試數據進行預處理，並轉換為張量\n",
    "test_personality_list = ['INFJ', 'INTP', 'ENFP', 'INFP', 'INTJ', 'ENFP', 'INFP', 'ENTP', 'ENFP', 'ENFP']  # 加載測試數據，類似於您的訓練數據\n",
    "# 使用 personality_mapping 將人格類別轉換為 ID\n",
    "test_personality_ids = [personality_mapping[personality] for personality in test_personality_list]\n",
    "\n",
    "# 根據人格類別 ID 找到對應的對話編碼\n",
    "test_dialogues_encoded = [encoded_data[id][0] for id in test_personality_ids]\n",
    "\n",
    "# 填充對話編碼，使其長度與 input_size 相同\n",
    "max_dialogue_length = input_size\n",
    "padded_test_dialogues = [dialogue + [0] * (max_dialogue_length - len(dialogue)) for dialogue in test_dialogues_encoded]\n",
    "\n",
    "# 將對話編碼進行轉換，並轉換為張量\n",
    "test_dialogues_padded = pad_sequence([torch.tensor(dialogue, dtype=torch.float32) for dialogue in padded_test_dialogues], batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型進行預測\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(test_dialogues_padded)\n",
    "    predicted_personality_probs = torch.softmax(test_outputs, dim=1)\n",
    "\n",
    "# 找到最相近的人格及其概率\n",
    "closest_personality_id = torch.argmax(predicted_personality_probs, dim=1)\n",
    "closest_personality = [personality for personality, id in personality_mapping.items() if id == closest_personality_id[0].item()][0]\n",
    "closest_personality_prob = predicted_personality_probs[0][closest_personality_id[0]].item()\n",
    "\n",
    "# 輸出最相近的人格及其概率\n",
    "print(\"Closest Personality:\",closest_personality)\n",
    "print(\"Probability:\",closest_personality_prob)\n",
    "print(\"------------\")\n",
    "\n",
    "# 找到前四高的人格及其概率\n",
    "top_5_personality_probs, top_5_personality_ids = torch.topk(predicted_personality_probs, k=5)\n",
    "top_5_personality_probs = top_5_personality_probs[0]\n",
    "top_5_personality_ids = top_5_personality_ids[0]\n",
    "\n",
    "# 輸出前四高的人格及其概率\n",
    "with open(file_path, \"a\") as f:\n",
    "    f.write(\"\\n------------\\n\")\n",
    "    f.write(\"Closest Personality: {}\\n\".format(closest_personality))\n",
    "    f.write(\"Probability: {}\\n\".format(closest_personality_prob))\n",
    "    f.write(\"\\n------------\\n\")\n",
    "    \n",
    "    for i in range(5):\n",
    "        personality_id = top_5_personality_ids[i].item()\n",
    "        personality = [personality for personality, id in personality_mapping.items() if id == personality_id][0]\n",
    "        prob = top_5_personality_probs[i].item()\n",
    "        print(\"Top \", i + 1, \" Personality:\", personality)\n",
    "        print(\"\\nProbability:\", prob , \"\\n\")\n",
    "        f.write(\"Top \"+ str(i + 1) + \" Personality:\"+ personality)\n",
    "        f.write(\"\\nProbability:\"+ str(prob) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07783039",
   "metadata": {},
   "source": [
    "測試SMOTE\n",
    "目前:epoch=60,hidden_size=128,L2,stepLR=10,lr=0.05,earlystop,crs,drop=0.5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
