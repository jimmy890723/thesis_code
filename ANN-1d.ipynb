{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81240fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b46b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...\n",
       "1  ENTP  ['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...\n",
       "2  INTP  ['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...\n",
       "3  INTJ  ['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...\n",
       "4  ENTJ  ['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/LSTM/mbti_to_LSTM_DF.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92e28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0,\n",
    "                        'ENTP': 1,\n",
    "                        'INTP': 2,\n",
    "                        'INTJ': 3,\n",
    "                        'ENTJ': 4,\n",
    "                        'ENFJ': 5,\n",
    "                        'INFP': 6,\n",
    "                        'ENFP': 7,\n",
    "                        'ISFP': 8,\n",
    "                        'ISTP': 9,\n",
    "                        'ISFJ': 10,\n",
    "                        'ISTJ': 11,\n",
    "                        'ESTP': 12,\n",
    "                        'ESFP': 13,\n",
    "                        'ESTJ': 14,\n",
    "                        'ESFJ': 15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e902e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((dialogue_ids, target_personality_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a10e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動態計算 input_size\n",
    "max_dialogue_length = max(len(dialogue) for dialogue, _ in encoded_data)\n",
    "input_size = max_dialogue_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd613b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列並轉換為張量\n",
    "padded_dialogues = [torch.tensor(dialogue, dtype=torch.float32) for dialogue, _ in encoded_data]\n",
    "padded_dialogues = pad_sequence(padded_dialogues, batch_first=True)\n",
    "\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402c9b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([392847, 1])\n",
      "torch.Size([392847])\n"
     ]
    }
   ],
   "source": [
    "# 将 padded_dialogues 从2D转换为1D张量\n",
    "padded_dialogues_1d = padded_dialogues.view(-1)\n",
    "\n",
    "# 创建新的目标数据和新的对话数据\n",
    "new_target_personality = []\n",
    "new_padded_dialogues = []\n",
    "\n",
    "# 遍历原始数据，并为每个对话生成对应的目标数据\n",
    "for i in range(len(encoded_data)):\n",
    "    target = encoded_data[i][1]  # 原始的目标数据\n",
    "    dialogues = encoded_data[i][0]  # 原始的对话数据\n",
    "\n",
    "    # 为每个对话生成新的对话数据\n",
    "    for dialogue in dialogues:\n",
    "        new_target_personality.append(target)\n",
    "        new_padded_dialogues.append([dialogue])\n",
    "\n",
    "# 转换为张量\n",
    "new_target_personality = torch.tensor(new_target_personality, dtype=torch.float32)\n",
    "new_padded_dialogues = pad_sequence([torch.tensor(dialogue, dtype=torch.float32) for dialogue in new_padded_dialogues], batch_first=True)\n",
    "\n",
    "# 检查结果的形状\n",
    "print(new_padded_dialogues.shape)\n",
    "print(new_target_personality.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d28f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 ANN 模型\n",
    "class PersonalityPredictionANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_prob=0.5):\n",
    "        super(PersonalityPredictionANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a6361a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集切分為訓練集和驗證集\n",
    "train_dialogues, val_dialogues, train_target, val_target = train_test_split(new_padded_dialogues, new_target_personality, test_size=0.15, random_state=42)\n",
    "\n",
    "# 初始化模型\n",
    "hidden_size = 128\n",
    "output_size = len(personality_mapping)\n",
    "input_size = 1\n",
    "model = PersonalityPredictionANN(input_size, hidden_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb36b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a6c2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#早停\n",
    "patience = 10  # 設定早期停止的耐心值\n",
    "best_val_loss = float('inf')\n",
    "counter = 0  # 用於計算連續的驗證損失沒有改善的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426e007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 2.2855\n",
      "Validation Loss: 2.2625, Validation Accuracy: 22.5784%\n",
      "Epoch [2/60], Loss: 2.2722\n",
      "Validation Loss: 2.2628, Validation Accuracy: 22.0167%\n",
      "Epoch [3/60], Loss: 2.2678\n",
      "Validation Loss: 2.2652, Validation Accuracy: 22.0167%\n",
      "Epoch [4/60], Loss: 2.2679\n",
      "Validation Loss: 2.2642, Validation Accuracy: 22.0167%\n",
      "Epoch [5/60], Loss: 2.2690\n",
      "Validation Loss: 2.2637, Validation Accuracy: 22.0167%\n",
      "Epoch [6/60], Loss: 2.2670\n",
      "Validation Loss: 2.2629, Validation Accuracy: 22.0167%\n",
      "Epoch [7/60], Loss: 2.2664\n",
      "Validation Loss: 2.2630, Validation Accuracy: 22.0167%\n",
      "Epoch [8/60], Loss: 2.2659\n",
      "Validation Loss: 2.2615, Validation Accuracy: 22.4274%\n",
      "Epoch [9/60], Loss: 2.2651\n",
      "Validation Loss: 2.2607, Validation Accuracy: 22.6106%\n",
      "Epoch [10/60], Loss: 2.2644\n",
      "Validation Loss: 2.2618, Validation Accuracy: 22.4274%\n",
      "Epoch [11/60], Loss: 2.2623\n",
      "Validation Loss: 2.2575, Validation Accuracy: 22.5784%\n",
      "Epoch [12/60], Loss: 2.2594\n",
      "Validation Loss: 2.2556, Validation Accuracy: 22.6106%\n",
      "Epoch [13/60], Loss: 2.2581\n",
      "Validation Loss: 2.2559, Validation Accuracy: 22.6106%\n",
      "Epoch [14/60], Loss: 2.2586\n",
      "Validation Loss: 2.2551, Validation Accuracy: 22.4274%\n",
      "Epoch [15/60], Loss: 2.2584\n",
      "Validation Loss: 2.2549, Validation Accuracy: 22.6106%\n",
      "Epoch [16/60], Loss: 2.2571\n",
      "Validation Loss: 2.2533, Validation Accuracy: 22.6106%\n",
      "Epoch [17/60], Loss: 2.2567\n",
      "Validation Loss: 2.2519, Validation Accuracy: 22.6106%\n",
      "Epoch [18/60], Loss: 2.2562\n",
      "Validation Loss: 2.2524, Validation Accuracy: 22.6106%\n",
      "Epoch [19/60], Loss: 2.2563\n",
      "Validation Loss: 2.2529, Validation Accuracy: 22.4274%\n",
      "Epoch [20/60], Loss: 2.2570\n",
      "Validation Loss: 2.2537, Validation Accuracy: 22.6106%\n",
      "Epoch [21/60], Loss: 2.2570\n",
      "Validation Loss: 2.2525, Validation Accuracy: 22.4274%\n",
      "Epoch [22/60], Loss: 2.2571\n",
      "Validation Loss: 2.2544, Validation Accuracy: 22.4274%\n",
      "Epoch [23/60], Loss: 2.2572\n",
      "Validation Loss: 2.2520, Validation Accuracy: 22.6106%\n",
      "Epoch [24/60], Loss: 2.2566\n",
      "Validation Loss: 2.2533, Validation Accuracy: 22.6106%\n",
      "Epoch [25/60], Loss: 2.2576\n",
      "Validation Loss: 2.2545, Validation Accuracy: 22.4274%\n",
      "Epoch [26/60], Loss: 2.2568\n",
      "Validation Loss: 2.2530, Validation Accuracy: 22.6106%\n",
      "Epoch [27/60], Loss: 2.2567\n",
      "Validation Loss: 2.2516, Validation Accuracy: 22.4274%\n",
      "Epoch [28/60], Loss: 2.2568\n",
      "Validation Loss: 2.2530, Validation Accuracy: 22.6106%\n",
      "Epoch [29/60], Loss: 2.2570\n",
      "Validation Loss: 2.2515, Validation Accuracy: 22.4274%\n",
      "Epoch [30/60], Loss: 2.2567\n",
      "Validation Loss: 2.2525, Validation Accuracy: 22.4274%\n",
      "Epoch [31/60], Loss: 2.2577\n",
      "Validation Loss: 2.2529, Validation Accuracy: 22.6106%\n",
      "Epoch [32/60], Loss: 2.2586\n",
      "Validation Loss: 2.2539, Validation Accuracy: 22.4274%\n",
      "Epoch [33/60], Loss: 2.2591\n",
      "Validation Loss: 2.2568, Validation Accuracy: 22.4274%\n",
      "Epoch [34/60], Loss: 2.2590\n",
      "Validation Loss: 2.2545, Validation Accuracy: 22.2000%\n",
      "Epoch [35/60], Loss: 2.2596\n",
      "Validation Loss: 2.2536, Validation Accuracy: 22.0167%\n",
      "Epoch [36/60], Loss: 2.2596\n",
      "Validation Loss: 2.2554, Validation Accuracy: 22.0167%\n",
      "Epoch [37/60], Loss: 2.2579\n",
      "Validation Loss: 2.2520, Validation Accuracy: 22.6106%\n",
      "Epoch [38/60], Loss: 2.2575\n",
      "Validation Loss: 2.2549, Validation Accuracy: 22.3510%\n",
      "Epoch [39/60], Loss: 2.2579\n",
      "Validation Loss: 2.2535, Validation Accuracy: 22.2000%\n",
      "Early Stopping: Validation loss has not improved for 10 epochs. Stopping training.\n",
      "E.I: 1756794/2298192 \n",
      "Accuracy: 0.7644243822970405\n",
      "\n",
      "S.N: 1987635/2298192 \n",
      "Accuracy: 0.8648689926690198\n",
      "\n",
      "T.F: 1334242/2298192 \n",
      "Accuracy: 0.5805615892840981\n",
      "\n",
      "J.P: 1368533/2298192 \n",
      "Accuracy: 0.5954824488119357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/ANN/Model/1d/note.txt\", \"w\") as f:\n",
    "    num_epochs = 60\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    item_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 將模型設置為訓練模式\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for dialogue_batch, target_batch in zip(train_dialogues, train_target):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(dialogue_batch)\n",
    "            loss = criterion(outputs, target_batch.long())  # 使用交叉熵損失\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(train_dialogues)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "        f.write(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\\n\")\n",
    "        \n",
    "        # 驗證模型\n",
    "        model.eval()  # 將模型設置為評估模式\n",
    "        correct_predictions = 0\n",
    "        total_samples = len(val_dialogues)\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for dialogue_batch, target_batch in zip(val_dialogues, val_target):\n",
    "                outputs = model(dialogue_batch)\n",
    "                loss = criterion(outputs, target_batch.long())  # 使用交叉熵損失\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted_class = torch.argmax(outputs).item()\n",
    "                true_class = target_batch.item()\n",
    "\n",
    "                for personality, value in personality_mapping.items():\n",
    "                    if value == predicted_class:\n",
    "                        mbti_labels_pre = personality\n",
    "                        break\n",
    "                for personality, value in personality_mapping.items():\n",
    "                    if value == int(true_class):\n",
    "                        mbti_labels_tru = personality \n",
    "                        break\n",
    "\n",
    "                for n in range(4):\n",
    "                    if n == 0:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['E/I'] += 1\n",
    "                    elif n == 1:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['S/N'] += 1\n",
    "                    elif n == 2:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['T/F'] += 1\n",
    "                    elif n == 3:\n",
    "                        if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                            dimension_counts['J/P'] += 1\n",
    "\n",
    "                if predicted_class == true_class:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "        item_count += total_samples\n",
    "        average_val_loss = val_loss / len(val_dialogues)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {accuracy*100:.4f}%\")\n",
    "        f.write(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "        \n",
    "        # 檢查驗證損失是否改善\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        # 如果連續一定次數（耐心值）驗證損失沒有改善，則停止訓練\n",
    "        if counter >= patience:\n",
    "            print(f\"Early Stopping: Validation loss has not improved for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fea4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/JenMing/Desktop/MBTI/ANN/Model/1d/best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
