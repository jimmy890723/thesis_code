{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60af66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.functional import softmax\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ee5376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ['INFP', 'INFP', 'INFJ', 'ENFP', 'ISTP', 'INTP...\n",
       "1  ENTP  ['INTJ', 'INTP', 'ENFP', 'INTJ', 'INTP', 'INTP...\n",
       "2  INTP  ['INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ...\n",
       "3  INTJ  ['INTJ', 'ISFJ', 'INFP', 'INTP', 'INTP', 'INTP...\n",
       "4  ENTJ  ['ENTJ', 'INTP', 'ENFP', 'INTP', 'ENTJ', 'INTJ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/LSTM/mbti_to_LSTM_DF.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025353b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0,\n",
    "                        'ENTP': 1,\n",
    "                        'INTP': 2,\n",
    "                        'INTJ': 3,\n",
    "                        'ENTJ': 4,\n",
    "                        'ENFJ': 5,\n",
    "                        'INFP': 6,\n",
    "                        'ENFP': 7,\n",
    "                        'ISFP': 8,\n",
    "                        'ISTP': 9,\n",
    "                        'ISFJ': 10,\n",
    "                        'ISTJ': 11,\n",
    "                        'ESTP': 12,\n",
    "                        'ESFP': 13,\n",
    "                        'ESTJ': 14,\n",
    "                        'ESFJ': 15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb8aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((dialogue_ids, target_personality_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ed01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將每個對話轉換為列表\n",
    "encoded_data = [(list(dialogue), target) for dialogue, target in encoded_data]\n",
    "padded_dialogues = pad_sequence([torch.tensor(dialogue, dtype=torch.long) for dialogue, _ in encoded_data], batch_first=True)\n",
    "\n",
    "# 動態計算 input_size\n",
    "max_dialogue_length = max(len(dialogue) for dialogue, _ in encoded_data)\n",
    "\n",
    "# 將目標轉換為PyTorch張量\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9af5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義CNN模型\n",
    "class PersonalityPredictionCNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_filters, kernel_size):\n",
    "        super(PersonalityPredictionCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, 64)  # 嵌入層\n",
    "        self.conv1 = nn.Conv1d(64, num_filters, kernel_size)  # 第一個卷積層\n",
    "        self.relu = nn.ReLU()  # ReLU激活函數\n",
    "        self.fc = nn.Linear(num_filters, num_classes)  # 全連接層\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)  # 將維度進行調整\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.max(x, dim=2)[0]  # 使用最大池化\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526f3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenMing\\AppData\\Local\\Temp\\ipykernel_10376\\955819853.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dialogues = [torch.tensor(dialogue, dtype=torch.long) for dialogue in padded_dialogues]\n",
      "C:\\Users\\JenMing\\AppData\\Local\\Temp\\ipykernel_10376\\955819853.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_target = torch.tensor(target_personality, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# 將序列轉換為張量\n",
    "train_dialogues = [torch.tensor(dialogue, dtype=torch.long) for dialogue in padded_dialogues]\n",
    "train_target = torch.tensor(target_personality, dtype=torch.long)\n",
    "\n",
    "# 創建包含元組的列表\n",
    "train_data_tuples = [(dialogue, target) for dialogue, target in zip(train_dialogues, train_target)]\n",
    "\n",
    "# 創建 TensorDataset，分別傳遞對話和目標\n",
    "train_dataset = TensorDataset(torch.stack(train_dialogues), train_target)\n",
    "\n",
    "# 切分訓練集和驗證集\n",
    "train_size = int(0.85 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# 創建 DataLoader\n",
    "batch_size = 32  # 設置批次大小\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc148e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "input_size = len(personality_mapping)\n",
    "num_classes = len(personality_mapping)\n",
    "num_filters = 128  # 卷積層的濾波器數量\n",
    "kernel_size = 3   # 卷積核大小\n",
    "model = PersonalityPredictionCNN(input_size, num_classes, num_filters, kernel_size)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5fabf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/JenMing/Desktop/MBTI/CNN/Model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4af1857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [1/10], Train Loss: 1.2122, Val Loss: 128.7268, Val Accuracy: 0.2604\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [2/10], Train Loss: 1.2148, Val Loss: 130.5601, Val Accuracy: 0.2911\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [3/10], Train Loss: 1.2115, Val Loss: 127.8226, Val Accuracy: 0.2680\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [4/10], Train Loss: 1.2164, Val Loss: 126.7238, Val Accuracy: 0.2688\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [5/10], Train Loss: 1.2131, Val Loss: 128.2451, Val Accuracy: 0.2757\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [6/10], Train Loss: 1.2151, Val Loss: 128.1582, Val Accuracy: 0.2596\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [7/10], Train Loss: 1.2033, Val Loss: 128.3489, Val Accuracy: 0.2719\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [8/10], Train Loss: 1.2115, Val Loss: 130.0447, Val Accuracy: 0.2757\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ']\n",
      "\n",
      "\n",
      "Epoch [9/10], Train Loss: 1.2164, Val Loss: 127.2892, Val Accuracy: 0.2711\n",
      "['INFJ', 'INTP', 'INTJ', 'ENTJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ESFJ']\n",
      "\n",
      "\n",
      "['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISTJ', 'ESTP']\n",
      "\n",
      "\n",
      "Epoch [10/10], Train Loss: 1.2106, Val Loss: 128.3690, Val Accuracy: 0.2873\n"
     ]
    }
   ],
   "source": [
    "# 設定訓練參數\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        dialogues, targets = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(dialogues)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # 在每個 epoch 結束後評估模型\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_predictions = []\n",
    "    val_target = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        a=1\n",
    "        for batch in val_loader:\n",
    "            dialogues, targets = batch\n",
    "            val_target.extend(targets.cpu().numpy())\n",
    "            val_outputs = model(dialogues)\n",
    "            batch_loss = criterion(val_outputs, targets)\n",
    "            val_loss += batch_loss.item()\n",
    "            val_predictions.extend(val_outputs.argmax(dim=1).cpu().numpy())\n",
    "            \n",
    "            # 使用編碼轉換映射\n",
    "            mbti_labels_pre = [key for key, value in personality_mapping.items() if value in val_predictions]\n",
    "            mbti_labels_tar = [key for key, value in personality_mapping.items() if value in val_target]\n",
    "\n",
    "            if a == 1:\n",
    "                print(mbti_labels_tar)\n",
    "                print(\"\\n\")\n",
    "                print(mbti_labels_pre)\n",
    "                print(\"\\n\")\n",
    "                a += 1\n",
    "\n",
    "    val_accuracy = accuracy_score(val_target, val_predictions)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {average_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a = 1\n",
    "    for batch in val_loader:  # 使用 DataLoader 來遍歷驗證數據\n",
    "        dialogues, targets = batch\n",
    "        val_outputs = model(dialogues)\n",
    "        batch_loss = criterion(val_outputs, targets)\n",
    "        val_loss += batch_loss.item()\n",
    "        val_predictions.extend(val_outputs.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        # 使用編碼轉換映射\n",
    "        mbti_labels_pre = [key for key, value in personality_mapping.items() if value in val_predictions]\n",
    "        mbti_labels_tar = [key for key, value in personality_mapping.items() if value in targets]\n",
    "        \n",
    "        if a == 1:\n",
    "            print(\"Validation Examples:\")\n",
    "            for i in range(10):  # 打印前10個示例\n",
    "                print(f\"Example {i+1}: Target = {mbti_labels_tar[i]}, Prediction = {mbti_labels_pre[i]}\")\n",
    "            print(\"\\n\")\n",
    "            a += 1\n",
    "\n",
    "val_accuracy = accuracy_score(val_target, val_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a44797",
   "metadata": {},
   "source": [
    "with open(file_path+\"note.txt\", \"w\") as f:\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    item_count = 0\n",
    "    \n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:  # 使用 DataLoader 來遍歷訓練數據\n",
    "            dialogues, targets = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(dialogues)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # 在每個 epoch 結束後評估模型\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_target = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            a = 1\n",
    "            for batch in val_loader:  # 使用 DataLoader 來遍歷驗證數據\n",
    "                dialogues, targets = batch\n",
    "                val_outputs = model(dialogues)\n",
    "                batch_loss = criterion(val_outputs, targets)\n",
    "                val_loss += batch_loss.item()\n",
    "                val_predictions.extend(val_outputs.argmax(dim=1).cpu().numpy())\n",
    "                \n",
    "                val_target.extend(targets.cpu().numpy())\n",
    "                \n",
    "                # 使用編碼轉換映射\n",
    "                mbti_labels_pre = [key for key, value in personality_mapping.items() if value in val_predictions]\n",
    "                mbti_labels_tar = [key for key, value in personality_mapping.items() if value in targets]\n",
    "                \n",
    "                print(\"Val outputs shape:\", val_outputs.shape)\n",
    "                print(\"Val targets shape:\", targets.shape)\n",
    "                \n",
    "    \n",
    "                if a == 1:\n",
    "                    print(mbti_labels_pre)\n",
    "                    print(\"\\n\")\n",
    "                    print(mbti_labels_tar)\n",
    "                    print(\"\\n\")\n",
    "                    a +=1\n",
    "                '''\n",
    "                for n in range(4):\n",
    "                    if n == 0:\n",
    "                        if val_predictions[0][n] == val_target[n]:\n",
    "                            dimension_counts['E/I'] += 1\n",
    "                    elif n == 1:\n",
    "                        if val_predictions[0][n] == val_target[n]:\n",
    "                            dimension_counts['S/N'] += 1\n",
    "                    elif n == 2:\n",
    "                        if val_predictions[0][n] == val_target[n]:\n",
    "                            dimension_counts['T/F'] += 1\n",
    "                    elif n == 3:\n",
    "                        if val_predictions[0][n] == val_target[n]:\n",
    "                            dimension_counts['J/P'] += 1\n",
    "                item_count += 1\n",
    "                '''\n",
    "\n",
    "        val_accuracy = accuracy_score(val_target, val_predictions)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {average_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        f.write(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {average_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        '''\n",
    "        EI_counts = dimension_counts['E/I']\n",
    "        SN_counts = dimension_counts['S/N']\n",
    "        TF_counts = dimension_counts['T/F']\n",
    "        JP_counts = dimension_counts['J/P']\n",
    "        print(f'E.I: {EI_counts}/{item_count} ')\n",
    "        print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "        print(f'S.N: {SN_counts}/{item_count} ')\n",
    "        print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "        print(f'T.F: {TF_counts}/{item_count} ')\n",
    "        print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "        print(f'J.P: {JP_counts}/{item_count} ')\n",
    "        print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "\n",
    "        f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "        f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "        f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "        f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "        f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "        f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "        f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "        f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "        '''\n",
    "        # 保存模型\n",
    "        torch.save(model.state_dict(), file_path+'cnn_model.pth')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a1b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
