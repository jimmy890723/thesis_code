{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba84c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a119f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取數據\n",
    "df = pd.read_csv('C:/Users/JenMing/Desktop/MBTI/one_type_one_sentence/mbti_to_LSTM_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7142a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼轉換\n",
    "personality_mapping = {'INFJ': 0, 'ENTP': 1, 'INTP': 2, 'INTJ': 3, 'ENTJ': 4, 'ENFJ': 5, 'INFP': 6, 'ENFP': 7, \n",
    "                       'ISFP': 8, 'ISTP': 9, 'ISFJ': 10, 'ISTJ': 11, 'ESTP': 12, 'ESFP': 13, 'ESTJ': 14, 'ESFJ': 15 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入和轉換\n",
    "encoded_data = []\n",
    "\n",
    "chars_to_remove = \"][' \"    \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_counts = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0}\n",
    "    mbti_per_count = []\n",
    "    dialogues = row[\"posts\"] #字串\n",
    "    target_personality = row[\"type\"]\n",
    "    for char in chars_to_remove:\n",
    "        dialogues = dialogues.replace(char, \"\")\n",
    "    \n",
    "    dialogues_list = dialogues.split(',')\n",
    "    \n",
    "    \n",
    "    dialogue_ids = [personality_mapping[personality] for personality in dialogues_list]\n",
    "    \n",
    "    for personality_id in dialogue_ids:\n",
    "        mbti_counts[personality_id] += 1\n",
    "    \n",
    "    for i in range(len(personality_mapping)):\n",
    "        mbti_per_count.append(round(mbti_counts[i]/len(dialogue_ids), 2))\n",
    "    \n",
    "    target_personality_id = personality_mapping[target_personality]\n",
    "    \n",
    "    encoded_data.append((mbti_per_count, target_personality_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5069d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列並轉換為張量\n",
    "input_data = torch.tensor([feature for feature, _ in encoded_data], dtype=torch.float32)\n",
    "target_personality = torch.tensor([target for _, target in encoded_data], dtype=torch.int64)  # 使用int64类型，因为它是类别标签\n",
    "\n",
    "# 資料集切分為訓練集和驗證集\n",
    "#train_dialogues, val_dialogues, train_target, val_target = train_test_split(input_data, target_personality, test_size=0.15, random_state=42)\n",
    "\n",
    "# 資料集切分為訓練集和驗證集\n",
    "train_dialogues, X_temp, train_target, y_temp = train_test_split(input_data, target_personality, test_size=0.3, random_state=42)\n",
    "\n",
    "# 进一步划分剩余的数据为验证集和测试集\n",
    "val_dialogues, X_test, val_target, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9c33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將你的訓練數據和測試數據轉換為NumPy數組\n",
    "X_train = train_dialogues.numpy()\n",
    "y_train = train_target.numpy()\n",
    "X_val = val_dialogues.numpy()\n",
    "Y_val = val_target.numpy()\n",
    "X_test = X_test.numpy()\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4edef419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Validation Accuracy: 0.9900076863950807\n"
     ]
    }
   ],
   "source": [
    "# 創建隨機森林分類器\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 定義網格搜索的超參數組合\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # 嘗試不同的樹的數量\n",
    "    'max_depth': [None, 10, 20, 30],  # 嘗試不同的最大深度\n",
    "    'min_samples_split': [2, 5, 10]  # 嘗試不同的最小樣本分裂數\n",
    "}\n",
    "\n",
    "# 使用網格搜索進行超參數調優\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5)  # 使用5折交叉驗證\n",
    "\n",
    "# 訓練模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 找到最佳超參數組合\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "# 使用最佳超參數訓練最終模型\n",
    "best_rf_classifier = RandomForestClassifier(**best_params)\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = best_rf_classifier.predict(X_val)\n",
    "\n",
    "# 計算驗證準確度\n",
    "val_accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbaff1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = y_pred\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(val_target, predicted_labels)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(val_target, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1262e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 99.0008%\n",
      "E.I: 1300/1301 \n",
      "Accuracy: 0.9992313604919293\n",
      "\n",
      "S.N: 1298/1301 \n",
      "Accuracy: 0.9976940814757879\n",
      "\n",
      "T.F: 1292/1301 \n",
      "Accuracy: 0.9930822444273636\n",
      "\n",
      "J.P: 1295/1301 \n",
      "Accuracy: 0.9953881629515757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/JenMing/Desktop/MBTI/random_forest/note.txt\", \"w\") as f:\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    correct_predictions = 0\n",
    "\n",
    "    item_count = len(predicted_labels)\n",
    "    \n",
    "    for n in range(len(predicted_labels)):\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == predicted_labels[n]:\n",
    "                mbti_labels_pre = personality\n",
    "                break\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == val_target[n]:\n",
    "                mbti_labels_tru = personality \n",
    "                break\n",
    "\n",
    "        if mbti_labels_pre == mbti_labels_tru:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        for n in range(4):\n",
    "            if n == 0:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['E/I'] += 1\n",
    "            elif n == 1:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['S/N'] += 1\n",
    "            elif n == 2:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['T/F'] += 1\n",
    "            elif n == 3:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['J/P'] += 1\n",
    "\n",
    "\n",
    "    accuracy = correct_predictions / len(predicted_labels) \n",
    "\n",
    "    #f.write(f\"del_count: {total_del_count_times}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.2f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.2f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.2f}\\n\\n\")\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy*100:.4f}%\")\n",
    "    f.write(f\"Validation Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "    \n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81aea0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2 11 ...  5  8  0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aac68d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/JenMing/Desktop/MBTI/random_forest/RF_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存Random Forest模型\n",
    "model_filename = 'C:/Users/JenMing/Desktop/MBTI/random_forest/RF_model.pkl'\n",
    "\n",
    "# 保存模型到文件\n",
    "joblib.dump(best_rf_classifier, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b490e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從文件載入模型\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "# 使用載入的模型進行預測\n",
    "new_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee2ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(y_test, new_predictions)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(y_test, new_predictions, average='weighted')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(y_test, new_predictions, average='weighted')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(y_test, new_predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec6639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.9247%\n",
      "E.I: 1299/1302 \n",
      "Accuracy: 0.9976958525345622\n",
      "\n",
      "S.N: 1297/1302 \n",
      "Accuracy: 0.9961597542242704\n",
      "\n",
      "T.F: 1296/1302 \n",
      "Accuracy: 0.9953917050691244\n",
      "\n",
      "J.P: 1294/1302 \n",
      "Accuracy: 0.9938556067588326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = new_predictions\n",
    "\n",
    "with open(\"C:/Users/JenMing/Desktop/MBTI/random_forest/note.txt\", \"w\") as f:\n",
    "    dimension_counts = {'E/I': 0,\n",
    "                        'S/N': 0,\n",
    "                        'T/F': 0,\n",
    "                        'J/P': 0}\n",
    "    correct_predictions = 0\n",
    "\n",
    "    item_count = len(predicted_labels)\n",
    "    \n",
    "    for n in range(len(predicted_labels)):\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == predicted_labels[n]:\n",
    "                mbti_labels_pre = personality\n",
    "                break\n",
    "        for personality, value in personality_mapping.items():\n",
    "            if value == y_test[n]:\n",
    "                mbti_labels_tru = personality \n",
    "                break\n",
    "\n",
    "        if mbti_labels_pre == mbti_labels_tru:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        for n in range(4):\n",
    "            if n == 0:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['E/I'] += 1\n",
    "            elif n == 1:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['S/N'] += 1\n",
    "            elif n == 2:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['T/F'] += 1\n",
    "            elif n == 3:\n",
    "                if mbti_labels_pre[n] == mbti_labels_tru[n]:\n",
    "                    dimension_counts['J/P'] += 1\n",
    "\n",
    "\n",
    "    accuracy = correct_predictions / len(predicted_labels) \n",
    "\n",
    "    #f.write(f\"del_count: {total_del_count_times}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.2f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.2f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.2f}\\n\\n\")\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy*100:.4f}%\")\n",
    "    f.write(f\"Test Accuracy: {accuracy*100:.4f}%\\n\")\n",
    "    \n",
    "    EI_counts = dimension_counts['E/I']\n",
    "    SN_counts = dimension_counts['S/N']\n",
    "    TF_counts = dimension_counts['T/F']\n",
    "    JP_counts = dimension_counts['J/P']\n",
    "    print(f'E.I: {EI_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    print(f'S.N: {SN_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    print(f'T.F: {TF_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    print(f'J.P: {JP_counts}/{item_count} ')\n",
    "    print('Accuracy: '+ str(JP_counts/item_count)+'\\n')\n",
    "    \n",
    "    f.write(f'E.I: {EI_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(EI_counts/item_count)+'\\n')\n",
    "    f.write(f'S.N: {SN_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(SN_counts/item_count)+'\\n')\n",
    "    f.write(f'T.F: {TF_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(TF_counts/item_count)+'\\n')\n",
    "    f.write(f'J.P: {JP_counts}/{item_count} ')\n",
    "    f.write('Accuracy: '+ str(JP_counts/item_count)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
